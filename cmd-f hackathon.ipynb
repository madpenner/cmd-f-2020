{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs103 import *\n",
    "from typing import NamedTuple, List\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Case = NamedTuple(\"Case\", [('number', int), ('prov', str), ('country', str), \n",
    "                           ('conf', float), ('death', float), ('recov', float)])\n",
    "#interp. a Case has a\n",
    "# serial number, Province/State, Country, Confirmed cases, Deaths, Recovered\n",
    "\n",
    "@typecheck\n",
    "def fn_for_case(c: Case)->...:  \n",
    "    return...(c.number,\n",
    "              c.prov,\n",
    "              c.country,\n",
    "              c.conf, \n",
    "              c.death,\n",
    "              c.recov)\n",
    "\n",
    "BASECASE = Case(0, \"None\", \"None\", 0, 0, 0)\n",
    "C1 = Case(1, \"Anhui\", \"China\", 1.0, 0.0, 0.0)\n",
    "C2 = Case(2, \"Beijing\", \"China\", 14.0, 0.0, 0.0)\n",
    "C3 = Case(3, \"Chongqing\", \"China\", 6.0, 0.0, 0.0)\n",
    "C4 = Case(4, \"Fujian\", \"China\", 1.0, 0.0, 0.0)\n",
    "\n",
    "@typecheck\n",
    "def fn_for_loc(loc: List[Case]) -> ...:   \n",
    "    # description of the accumulator           \n",
    "    acc = ...      # type: ...\n",
    "    for c in loc:\n",
    "        acc = ...(fn_for_case(c), acc)\n",
    "\n",
    "    return ...(acc)\n",
    "\n",
    "LOC0 = []\n",
    "LOC1 = [C1]\n",
    "LOC2 = [C1, C2, C3, C4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m3 of 3 tests passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### functions\n",
    "\n",
    "@typecheck\n",
    "def read(filename: str) -> List[Case]:\n",
    "    \"\"\"    \n",
    "    reads information from the specified file and returns a list of cases. Each Case has a\n",
    "    serial number, Province/State, Country, Confirmed cases, Deaths, Recovered\n",
    "    \"\"\"\n",
    "    #return [] #stub\n",
    "    # Template from HtDAP\n",
    "    # loc contains the result so far\n",
    "    loc = [] # type: List[Case]\n",
    "\n",
    "    with open(filename) as csvfile:\n",
    "        \n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) # skip header line\n",
    "\n",
    "        for row in reader:\n",
    "            # you may not need to store all the rows, and you may need\n",
    "            # to convert some of the strings to other types\n",
    "            c = Case(parse_int(row[0]), row[2], row[3], parse_float(row[5]), \n",
    "                     parse_float(row[6]), parse_float(row[7]))\n",
    "            loc.append(c)\n",
    "    \n",
    "    return loc\n",
    "\n",
    "#begin testing\n",
    "start_testing()\n",
    "\n",
    "expect(read('testfile_empty.csv'), [])\n",
    "expect(read('testfile_1case.csv'), [C1])\n",
    "expect(read(\"testfile_4case.csv\"), [C1, C2, C3, C4])\n",
    "\n",
    "summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fe889dcba771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2019_nCoV_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cs103/typecheck/typecheck.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The function \\x1b[34m%s\\x1b[0m is missing a type for the parameter %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'return'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0msubtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the returned value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-691cfb8e0492>\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# skip header line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'reader'"
     ]
    }
   ],
   "source": [
    "read('2019_nCoV_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTest failed:\u001b[0m expected [Case(number=2, prov='Beijing', country='China', conf=14.0, death=0.0, recov=0.0), Case(number=3, prov='Chongqing', country='China', conf=6.0, death=0.0, recov=0.0), Case(number=1, prov='Anhui', country='China', conf=1.0, death=0.0, recov=0.0), Case(number=4, prov='Fujian', country='China', conf=1.0, death=0.0, recov=0.0)] but got [Case(number=1, prov='Anhui', country='China', conf=1.0, death=0.0, recov=0.0), Case(number=2, prov='Beijing', country='China', conf=14.0, death=0.0, recov=0.0), Case(number=3, prov='Chongqing', country='China', conf=6.0, death=0.0, recov=0.0), Case(number=4, prov='Fujian', country='China', conf=1.0, death=0.0, recov=0.0)]\n",
      "   \u001b[1mLine 129: \u001b[0mexpect (sort_conf_cases (LOC2), [C2, C3, C1, C4])\n",
      "\u001b[91m22 of 23 tests passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@typecheck\n",
    "def is_bigger(n1: float, n2: float)-> bool:\n",
    "    \"\"\"\n",
    "    takes two numbers and returns True if the first is bigger than the second\n",
    "    \"\"\"\n",
    "    \n",
    "    if n1 == None:\n",
    "        return False\n",
    "    elif n2 == None:\n",
    "        return True\n",
    "    else:\n",
    "        return n1 > n2\n",
    "    \n",
    "@typecheck\n",
    "def more_confirmed(c1: Case, c2: Case)-> bool:\n",
    "    \"\"\"\n",
    "    takes two cases and returns true if the first case has more confirmed cases\n",
    "    \"\"\"\n",
    "    return c1.conf > c2.conf\n",
    "    \n",
    "@typecheck\n",
    "def most_confirmed_prov(loc: List[Case])-> str:\n",
    "    \"\"\"\n",
    "    takes a list of cases and returns the state/province with the most cases\n",
    "    \"\"\"\n",
    "    \n",
    "    biggest = BASECASE\n",
    "    \n",
    "    for c in loc:\n",
    "        if more_confirmed(c, biggest):\n",
    "            biggest = c\n",
    "        \n",
    "        \n",
    "    return biggest.prov\n",
    "\n",
    "@typecheck\n",
    "def most_confirmed_case(loc: List[Case])-> Case:\n",
    "    \"\"\"\n",
    "    takes a list of cases and returns the case with the most confirmed cases\n",
    "    \"\"\"\n",
    "    \n",
    "    biggest = BASECASE\n",
    "    \n",
    "    for c in loc:\n",
    "        if more_confirmed(c, biggest):\n",
    "            biggest = c       \n",
    "        \n",
    "    return biggest\n",
    "\n",
    "@typecheck\n",
    "def is_most_confirmed(c1: Case, loc: List[Case])-> bool:\n",
    "    \"\"\"\n",
    "    takes a list of cases and a case and returns true if that case is the most in the list\n",
    "    \"\"\"\n",
    "    return most_confirmed_case(loc) == c1\n",
    "\n",
    "@typecheck\n",
    "def partition(array, start, end):\n",
    "    pivot = array[start]\n",
    "    low = start + 1\n",
    "    high = end\n",
    "    \n",
    "    while True:\n",
    "        while low <= high and array[high] >= pivot:\n",
    "            high = high - 1\n",
    "        while low <= high and array[low] <= pivot:\n",
    "            low = low + 1\n",
    "        if low <= high:\n",
    "            array[low], array[high] = array[high], array[low]\n",
    "        else:\n",
    "            break\n",
    "    array[start], array[high] = array[high], array[start]\n",
    "    \n",
    "    return high\n",
    "\n",
    "@typecheck\n",
    "def quick_sort(array, start, end):\n",
    "    if start >= end:\n",
    "        return\n",
    "    p = partition(array, start, end)\n",
    "    quick_sort(array, start, p-1)\n",
    "    quick_sort(array, p+1, end)\n",
    "        \n",
    "\n",
    "@typecheck\n",
    "def sort_conf_cases(loc: List[Case])-> List[Case]:\n",
    "    \"\"\"\n",
    "    sorts the cases in order from case with most confirmed to least\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    biggest = BASECASE\n",
    "    for c in loc:\n",
    "        if more_confirmed(c, BASECASE):\n",
    "            biggest = c \n",
    "            acc = acc + [c]\n",
    "                  \n",
    "    return acc\n",
    "        \n",
    "    \n",
    "start_testing()\n",
    "\n",
    "expect (is_bigger(1, 2), False)\n",
    "expect (is_bigger(2, 1), True)\n",
    "expect (is_bigger(1, 1), False)\n",
    "\n",
    "expect (more_confirmed(BASECASE, C1), False)\n",
    "expect (more_confirmed(C1, BASECASE), True)\n",
    "expect (more_confirmed(C2, C1), True)\n",
    "expect (more_confirmed(C2, C4), True)\n",
    "expect (more_confirmed(C1, C3), False)\n",
    "\n",
    "expect (most_confirmed_prov(LOC0), \"None\")\n",
    "expect (most_confirmed_prov(LOC1), \"Anhui\")\n",
    "expect (most_confirmed_prov(LOC2), \"Beijing\")\n",
    "\n",
    "expect (most_confirmed_case(LOC0), BASECASE)\n",
    "expect (most_confirmed_case(LOC1), C1)\n",
    "expect (most_confirmed_case(LOC2), C2)\n",
    "\n",
    "expect (is_most_confirmed(BASECASE, LOC0), True)\n",
    "expect (is_most_confirmed(C1, LOC0), False)\n",
    "expect (is_most_confirmed(BASECASE, LOC1), False)\n",
    "expect (is_most_confirmed(C1, LOC1), True)\n",
    "expect (is_most_confirmed(C1, LOC2), False)\n",
    "expect (is_most_confirmed(C2, LOC2), True)\n",
    "\n",
    "expect (sort_conf_cases (LOC0), [])\n",
    "expect (sort_conf_cases (LOC1), [C1])\n",
    "expect (sort_conf_cases (LOC2), [C2, C3, C1, C4])\n",
    "\n",
    "summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hubei'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_confirmed_prov(read('2019_nCoV_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASECASE = Case(0, \"None\", \"None\", 0, 0, 0)\n",
    "C1 = Case(1, \"Anhui\", \"China\", 1.0, 0.0, 0.0)\n",
    "C2 = Case(2, \"Beijing\", \"China\", 14.0, 0.0, 0.0)\n",
    "C3 = Case(3, \"Chongqing\", \"China\", 6.0, 0.0, 0.0)\n",
    "C4 = Case(4, \"Fujian\", \"China\", 1.0, 0.0, 0.0)\n",
    "\n",
    "LOC0 = []\n",
    "LOC1 = [C1]\n",
    "LOC2 = [C1, C2, C3, C4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case(number=4, prov='Fujian', country='China', conf=1.0, death=0.0, recov=0.0)\n"
     ]
    }
   ],
   "source": [
    "print (C4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./2019_nCoV_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"Province/State\"]).apply(lambda x:x.sort_values([\"Confirmed\"], ascending = True)).drop_duplicates('Province/State', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Sno                 Date Province/State         Country  \\\n",
      "Province/State                                                                  \n",
      "Anhui          1649  1650  02/17/2020 22:00:00          Anhui  Mainland China   \n",
      "Arizona        471    472  01/31/2020 19:00:00        Arizona              US   \n",
      "Bavaria        487    488  01/31/2020 19:00:00        Bavaria         Germany   \n",
      "Beijing        1657  1658  02/17/2020 22:00:00        Beijing  Mainland China   \n",
      "Boston, MA     1712  1713  02/17/2020 22:00:00     Boston, MA              US   \n",
      "...                   ...                  ...            ...             ...   \n",
      "Victoria       1691  1692  02/17/2020 22:00:00       Victoria       Australia   \n",
      "Washington     468    469  01/31/2020 19:00:00     Washington              US   \n",
      "Xinjiang       1672  1673  02/17/2020 22:00:00       Xinjiang  Mainland China   \n",
      "Yunnan         1663  1664  02/17/2020 22:00:00         Yunnan  Mainland China   \n",
      "Zhejiang       1647  1648  02/17/2020 22:00:00       Zhejiang  Mainland China   \n",
      "\n",
      "                             Last Update  Confirmed  Deaths  Recovered  \n",
      "Province/State                                                          \n",
      "Anhui          1649  2020-02-17T09:13:07      973.0     6.0      280.0  \n",
      "Arizona        471   01/31/2020 19:00:00        1.0     0.0        0.0  \n",
      "Bavaria        487   01/31/2020 19:00:00        7.0     0.0        0.0  \n",
      "Beijing        1657  2020-02-17T01:23:02      381.0     4.0      114.0  \n",
      "Boston, MA     1712  2020-02-01T19:43:03        1.0     0.0        0.0  \n",
      "...                                  ...        ...     ...        ...  \n",
      "Victoria       1691  2020-02-13T17:53:03        4.0     0.0        4.0  \n",
      "Washington     468   01/31/2020 19:00:00        1.0     0.0        0.0  \n",
      "Xinjiang       1672  2020-02-17T01:53:01       75.0     1.0       12.0  \n",
      "Yunnan         1663  2020-02-17T10:23:04      171.0     0.0       47.0  \n",
      "Zhejiang       1647  2020-02-17T11:23:06     1171.0     0.0      507.0  \n",
      "\n",
      "[61 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
